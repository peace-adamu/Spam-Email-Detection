{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZDorMTukPgE"
      },
      "source": [
        "Natural Language Processing (NLP) tasks using Machine Learning techniques\n",
        "\n",
        "steps:\n",
        "\n",
        "Data Preprocessing: We'll discuss how to prepare and clean the data for NLP tasks. This includes tasks such as removing special characters, handling capitalization, tokenization, and dealing with stopwords.\n",
        "\n",
        "Data Vectorization: Next, we'll explore various methods for converting text data into numerical representations suitable for machine learning models. This includes techniques like TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "Model Training: We'll dive into training different machine learning models for NLP tasks. This involves selecting appropriate models like Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Naive Bayes, Decision Trees, Random Forests, and more. We'll evaluate their performance using metrics like accuracy, precision.\n",
        "\n",
        "a. Training and Evaluation: We'll train each model and evaluate its performance using various evaluation metrics to understand how well it generalizes to unseen data.\n",
        "\n",
        "b. Model Selection: Finally, we'll identify the model that demonstrates the best performance on our dataset and discuss strategies for model selection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9XOWSn1nv7X"
      },
      "source": [
        "###  Text Preprocessing\n",
        "\n",
        "| Library | Function |\n",
        "|--------|----------|\n",
        "| `string` | Provides tools to handle and manipulate strings, including punctuation removal. |\n",
        "| `re` | Regular expressions for pattern matching and text cleaning. |\n",
        "| `nltk.corpus.stopwords` | Contains lists of stopwords (common words like \"the\", \"is\") to remove from text. |\n",
        "| `nltk.stem.porter.PorterStemmer` | Reduces words to their root form (e.g., \"running\" → \"run\"). |\n",
        "\n",
        "---\n",
        "\n",
        "### Data Handling & Visualization\n",
        "\n",
        "| Library | Function |\n",
        "|--------|----------|\n",
        "| `numpy` | Supports numerical operations and array handling. |\n",
        "| `pandas` | Used for data manipulation and analysis with DataFrames. |\n",
        "| `matplotlib.pyplot` | Basic plotting library for visualizing data. |\n",
        "| `seaborn` | Built on matplotlib; provides more attractive and informative statistical graphics. |\n",
        "\n",
        "---\n",
        "\n",
        "###  Feature Extraction\n",
        "\n",
        "| Library | Function |\n",
        "|--------|----------|\n",
        "| `CountVectorizer` | Converts text to a matrix of token counts (Bag of Words model). |\n",
        "| `TfidfVectorizer` | Converts text to a matrix of TF-IDF features (term importance). |\n",
        "\n",
        "---\n",
        "\n",
        "###  Machine Learning Models\n",
        "\n",
        "| Library | Function |\n",
        "|--------|----------|\n",
        "| `LogisticRegression` | Linear classifier for binary/multiclass classification. |\n",
        "| `SVC` | Support Vector Classifier for separating data with hyperplanes. |\n",
        "| `GaussianNB`, `MultinomialNB`, `BernoulliNB` | Naive Bayes classifiers for different data distributions. |\n",
        "| `DecisionTreeClassifier` | Tree-based model that splits data based on feature values. |\n",
        "| `KNeighborsClassifier` | Classifies based on the majority label of nearest neighbors. |\n",
        "| `RandomForestClassifier` | Ensemble of decision trees for better accuracy and robustness. |\n",
        "| `AdaBoostClassifier` | Boosts weak learners sequentially to improve performance. |\n",
        "| `BaggingClassifier` | Trains multiple models on random subsets of data to reduce variance. |\n",
        "| `ExtraTreesClassifier` | Similar to Random Forest but uses more randomness in tree splits. |\n",
        "| `GradientBoostingClassifier` | Builds models sequentially to correct previous errors. |\n",
        "| `XGBClassifier` | Optimized gradient boosting library for high performance. |\n",
        "\n",
        "---\n",
        "\n",
        "###  Model Evaluation & Splitting\n",
        "\n",
        "| Library | Function |\n",
        "|--------|----------|\n",
        "| `train_test_split` | Splits data into training and testing sets. |\n",
        "| `sklearn.metrics` | Provides tools to evaluate model performance (accuracy, precision, recall, etc.). |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTXfg4WslicD"
      },
      "source": [
        "Importing Basis Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7J5iSTPahzj1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Punctuations\n",
        "import string\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "# Remove Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "# Regular Expressions\n",
        "import re\n",
        "# Import PorterStemmer from NLTK Library\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB , MultinomialNB , BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "# Metrix and Train Test\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDzGGfMBtano"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qP_wR5ISlbXN"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "df = pd.read_csv(\"emails.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xCqvuXHhpF1f",
        "outputId": "71b4fb84-a9df-4d8c-821d-c4ad9041f0f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5723</th>\n",
              "      <td>Subject: re : research and development charges...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5724</th>\n",
              "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>Subject: re : interest  david ,  please , call...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5728 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  spam\n",
              "0     Subject: naturally irresistible your corporate...     1\n",
              "1     Subject: the stock trading gunslinger  fanny i...     1\n",
              "2     Subject: unbelievable new homes made easy  im ...     1\n",
              "3     Subject: 4 color printing special  request add...     1\n",
              "4     Subject: do not have money , get software cds ...     1\n",
              "...                                                 ...   ...\n",
              "5723  Subject: re : research and development charges...     0\n",
              "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
              "5725  Subject: re : enron case study update  wow ! a...     0\n",
              "5726  Subject: re : interest  david ,  please , call...     0\n",
              "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
              "\n",
              "[5728 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "5TWWEf8ds6gn",
        "outputId": "6595ddb2-3e60-430a-bada-7c7e52ffe23c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null Values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT-k5J0puOBY"
      },
      "source": [
        "Our Dataset Contains No Null Values we Simply Move forward on the Text Preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kboglfhRszj8",
        "outputId": "4c08d988-d50c-488f-9a41-90ff46d1755b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5728 entries, 0 to 5727\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5728 non-null   object\n",
            " 1   spam    5728 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 89.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# Information check\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mrh9Gcpt7vM",
        "outputId": "8f0eb1dd-84bb-4388-ff53-8edb19f5ddcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(33)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Duplicates\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRpfaUNqubY_",
        "outputId": "65fdea19-fa40-44e6-80d5-400c86043234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicates values in Dataset is : 33\n"
          ]
        }
      ],
      "source": [
        "# Duplicates\n",
        "print(f\"Duplicates values in Dataset is : {df.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yn3p4zb3uo3v"
      },
      "outputs": [],
      "source": [
        "# Drop Duplicates\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Zvh6U9UEuxWP",
        "outputId": "180a1d09-60b9-4041-a08a-95a42595fdf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null Values Columns\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MazkME6uu3G5",
        "outputId": "4d053525-0aad-41a8-d3b8-25ba3773a3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject: naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
            "Subject: the stock trading gunslinger  fanny is merrill but muzo not colza attainder and penultimate like esmark perspicuous ramble is segovia not group try slung kansas tanzania yes chameleon or continuant clothesman no  libretto is chesapeake but tight not waterway herald and hawthorn like chisel morristown superior is deoxyribonucleic not clockwork try hall incredible mcdougall yes hepburn or einsteinian earmark no  sapling is boar but duane not plain palfrey and inflexible like huzzah pepperoni bedtime is nameable not attire try edt chronography optima yes pirogue or diffusion albeit no \n",
            "Subject: unbelievable new homes made easy  im wanting to show you this  homeowner  you have been pre - approved for a $ 454 , 169 home loan at a 3 . 72 fixed rate .  this offer is being extended to you unconditionally and your credit is in no way a factor .  to take advantage of this limited time opportunity  all we ask is that you visit our website and complete  the 1 minute post approval form  look foward to hearing from you ,  dorcas pittman\n"
          ]
        }
      ],
      "source": [
        "# Lets Check Some Text\n",
        "print(df['text'][0])\n",
        "print(df['text'][1])\n",
        "print(df['text'][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilsZv7VmHiS2"
      },
      "source": [
        "## Text Preprocessing\n",
        "Basis Text Preprocessing Like Cleaning Text , Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "mmsz7kx1vNxd",
        "outputId": "32caac86-d73b-4968-da10-22468ec4ed93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    subject: naturally irresistible your corporate...\n",
              "1    subject: the stock trading gunslinger  fanny i...\n",
              "2    subject: unbelievable new homes made easy  im ...\n",
              "3    subject: 4 color printing special  request add...\n",
              "4    subject: do not have money , get software cds ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. LowerCase\n",
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "# Head\n",
        "df['text'].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2U81CNQIPKC",
        "outputId": "2b4f9602-7d9c-4a1d-dee3-96b0163c7294"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7812\\2736969314.py:11: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df['text'] = df['text'].apply(lambda x: re.sub(\"\\s+\", \" \", x).strip())\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Remove all punctuation (like !, ?, @, $, etc.)\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", x))\n",
        "\n",
        "# If you want to remove other special symbols too, such as numbers, use:\n",
        "# df['text'] = df['text'].apply(lambda x: re.sub(\"[^A-Za-z\\s]\", \"\", x))\n",
        "\n",
        "# Optional: convert to lowercase\n",
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "# Optional: remove extra spaces\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(\"\\s+\", \" \", x).strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OX0wb8lGMC0g"
      },
      "outputs": [],
      "source": [
        "# 3. Remove @ From Train and Test Text\n",
        "df['text'] = df['text'].str.replace('@','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5qbFz2SVMjDk"
      },
      "outputs": [],
      "source": [
        "# 4. Remove URLs from Test and Train Text\n",
        "df['text'] = df['text'].str.replace(r'^https?:\\/\\/.*[\\r\\n]*','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NqJy7Rv8OipN"
      },
      "outputs": [],
      "source": [
        "# 5. Remove $ From Train and Test Text\n",
        "df['text'] = df['text'].str.replace('$','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vai7tJReOr7P",
        "outputId": "3adb36f9-6b54-44e3-9232-d47012834121"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BVZTwrQQI7DY",
        "outputId": "6ebdd7fe-d526-440d-e685-df03cdba023e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject naturally irresistible corporate ident...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject unbelievable new homes made easy im wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject 4 color printing special request addit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject money get software cds software compat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  subject naturally irresistible corporate ident...     1\n",
              "1  subject stock trading gunslinger fanny merrill...     1\n",
              "2  subject unbelievable new homes made easy im wa...     1\n",
              "3  subject 4 color printing special request addit...     1\n",
              "4  subject money get software cds software compat...     1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. Intilize Stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Apply Stopwords\n",
        "df['text'] = df['text'].apply(lambda x : ' '.join([word for word in x.split()if word not in (stop_words)]))\n",
        "\n",
        "# Head\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jIgvs9DIJI5I",
        "outputId": "38ab2bfc-e6a0-4925-b9c5-71a2563e0378"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject naturally irresistible corporate ident...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject unbelievable new homes made easy im wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject 4 color printing special request addit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject money get software cds software compat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  subject naturally irresistible corporate ident...     1\n",
              "1  subject stock trading gunslinger fanny merrill...     1\n",
              "2  subject unbelievable new homes made easy im wa...     1\n",
              "3  subject 4 color printing special request addit...     1\n",
              "4  subject money get software cds software compat...     1"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. Handling ChatWords: abbravations\n",
        "chat_words = {\n",
        "    \"u\": \"you\",\n",
        "    \"ur\": \"your\",\n",
        "    \"r\": \"are\",\n",
        "    \"btw\": \"by the way\",\n",
        "    \"idk\": \"I don't know\",\n",
        "    \"omg\": \"oh my god\",\n",
        "    \"lol\": \"laugh out loud\",\n",
        "    \"pls\": \"please\",\n",
        "    \"thx\": \"thanks\",\n",
        "    \"gr8\": \"great\",\n",
        "    \"b4\": \"before\"\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Function\n",
        "def chat_conversion(Text):\n",
        "    new_text = []\n",
        "    for i in Text.split():\n",
        "        if i.upper() in chat_words:\n",
        "            new_text.append(chat_words[i.upper()])\n",
        "        else:\n",
        "            new_text.append(i)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "# Calling Function\n",
        "df['text'] = df['text'].apply(chat_conversion)\n",
        "\n",
        "\n",
        "# Head\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "HSZeCuNIJ4cn",
        "outputId": "50440e0e-c967-459c-d1e5-12779237ee9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "      <th>text_sent_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject naturally irresistible corporate ident...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject naturally irresistible corporate iden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject stock trading gunslinger fanny merril...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject unbelievable new homes made easy im wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject unbelievable new homes made easy im w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject 4 color printing special request addit...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject 4 color printing special request addi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject money get software cds software compat...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject money get software cds software compa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam  \\\n",
              "0  subject naturally irresistible corporate ident...     1   \n",
              "1  subject stock trading gunslinger fanny merrill...     1   \n",
              "2  subject unbelievable new homes made easy im wa...     1   \n",
              "3  subject 4 color printing special request addit...     1   \n",
              "4  subject money get software cds software compat...     1   \n",
              "\n",
              "                                     text_sent_token  \n",
              "0  [subject naturally irresistible corporate iden...  \n",
              "1  [subject stock trading gunslinger fanny merril...  \n",
              "2  [subject unbelievable new homes made easy im w...  \n",
              "3  [subject 4 color printing special request addi...  \n",
              "4  [subject money get software cds software compa...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 8. Tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Apply sent_tokenize\n",
        "df['text_sent_token'] = df['text'].apply(sent_tokenize)\n",
        "\n",
        "# Head\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-5_ixtTK1aX",
        "outputId": "601fd995-fae1-49b4-b401-8178d7dc3a22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OZj9KPNFMykM",
        "outputId": "a9f2df5a-8322-474f-a025-1bab399373be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "      <th>text_sent_token</th>\n",
              "      <th>stem_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject naturally irresistible corporate ident...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject naturally irresistible corporate iden...</td>\n",
              "      <td>subject natur irresist corpor ident lt realli ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject stock trading gunslinger fanny merril...</td>\n",
              "      <td>subject stock trade gunsling fanni merril muzo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject unbelievable new homes made easy im wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject unbelievable new homes made easy im w...</td>\n",
              "      <td>subject unbeliev new home made easi im want sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject 4 color printing special request addit...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject 4 color printing special request addi...</td>\n",
              "      <td>subject 4 color print special request addit in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject money get software cds software compat...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject money get software cds software compa...</td>\n",
              "      <td>subject money get softwar cd softwar compat gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam  \\\n",
              "0  subject naturally irresistible corporate ident...     1   \n",
              "1  subject stock trading gunslinger fanny merrill...     1   \n",
              "2  subject unbelievable new homes made easy im wa...     1   \n",
              "3  subject 4 color printing special request addit...     1   \n",
              "4  subject money get software cds software compat...     1   \n",
              "\n",
              "                                     text_sent_token  \\\n",
              "0  [subject naturally irresistible corporate iden...   \n",
              "1  [subject stock trading gunslinger fanny merril...   \n",
              "2  [subject unbelievable new homes made easy im w...   \n",
              "3  [subject 4 color printing special request addi...   \n",
              "4  [subject money get software cds software compa...   \n",
              "\n",
              "                                            stem_msg  \n",
              "0  subject natur irresist corpor ident lt realli ...  \n",
              "1  subject stock trade gunsling fanni merril muzo...  \n",
              "2  subject unbeliev new home made easi im want sh...  \n",
              "3  subject 4 color print special request addit in...  \n",
              "4  subject money get softwar cd softwar compat gr...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 9. Stemming\n",
        "\n",
        "# Intilize Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# This Function Will Stem Words\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "# Calling\n",
        "df['stem_msg'] = df['text'].apply(stem_words)\n",
        "\n",
        "# Head\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qd-ESapNdyf"
      },
      "source": [
        "# Model Building\n",
        "Text Representation / Converting text Into Numbers\n",
        "\n",
        "We Do Text Vectorization. Text Vectorization is the Process of Converting Text into Numbers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g77Er9fvN2DL"
      },
      "source": [
        "Initialization:\n",
        "\n",
        "\n",
        "This line initializes a CountVectorizer object named cv with default parameters. CountVectorizer is a class provided by scikit-learn for converting a collection of text documents into a matrix of token counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FFA8fx3SNIK2"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbHeB8JHOD86"
      },
      "source": [
        "Fitting CountVectorizer on Text Data:\n",
        "\n",
        "\n",
        "cv.fit_transform(df['stem_msg']): This method fits the CountVectorizer to the text data in the 'stem_msg' column of the DataFrame df and transforms the text data into a sparse matrix representation. The fit_transform() method both learns the vocabulary from the text data and transforms the text data into a document-term matrix.\n",
        ".toarray(): This method converts the sparse matrix representation obtained from fit_transform() into a dense numpy array. This array, denoted by X, contains the document-term matrix where each row represents a document (message) and each column represents a unique word in the vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Er5HA6ryN5tb"
      },
      "outputs": [],
      "source": [
        "X = cv.fit_transform(df['stem_msg']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xcHcZmHOQXc",
        "outputId": "5201907c-478c-45e4-8984-b233472b65ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5695, 29254)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shape Of X\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE4nQrgMO7H8"
      },
      "source": [
        "# Encoding 'y'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2R0zhBOXO3TO"
      },
      "outputs": [],
      "source": [
        "# y\n",
        "y = df['spam']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLqn2Jg7D7df",
        "outputId": "6c5e30f3-e3cd-4644-8fe0-bac37ebcbc52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5695,)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shape of Y\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "BlXpOygwJzo6",
        "outputId": "6738368c-d2a9-4e4a-b9d6-3f6699377a25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "5723    0\n",
              "5724    0\n",
              "5725    0\n",
              "5726    0\n",
              "5727    0\n",
              "Name: spam, Length: 5695, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK6suzLYELTd"
      },
      "source": [
        "# Train Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-8cTJl7wD9le"
      },
      "outputs": [],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u76oMO6mEbNY"
      },
      "source": [
        "# Model Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33wEtnFWEj8k"
      },
      "source": [
        "#### 1. Support Vector Machine (SVM):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X_9vyp4iEZUW"
      },
      "outputs": [],
      "source": [
        "svc = SVC(kernel='sigmoid', gamma=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npFNo6cgEuXB"
      },
      "source": [
        "##### - This initializes an SVM classifier with a sigmoid kernel and a gamma value of 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un9aZXvUE5__"
      },
      "source": [
        "#### 2. K-Nearest Neighbors (KNN):*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pLMm1FGlEtSR"
      },
      "outputs": [],
      "source": [
        "knc = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcgujHnxFHhh"
      },
      "source": [
        "##### - This initializes a KNN classifier with default parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydQ7GfT8FX-p"
      },
      "source": [
        "#### 3. Multinomial Naive Bayes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vVAHe9MzFByQ"
      },
      "outputs": [],
      "source": [
        "mnb = MultinomialNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXzfSD7SGvmc"
      },
      "source": [
        "##### - This initializes a Multinomial Naive Bayes classifier, which is commonly used for text classification tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JgGRQzlG4uG"
      },
      "source": [
        "#### 4. Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3ltwmdW-Fmpf"
      },
      "outputs": [],
      "source": [
        "dtc = DecisionTreeClassifier(max_depth=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4dAOfzqHJ5k"
      },
      "source": [
        "##### - This initializes a decision tree classifier with a maximum depth of 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSNn2lK1HOtt"
      },
      "source": [
        "#### 5. Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-ziCHqG5HHbc"
      },
      "outputs": [],
      "source": [
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-BzYLrhHeMc"
      },
      "source": [
        "##### This initializes a logistic regression classifier with L1 regularization using the liblinear solver.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxT9asOrHln1"
      },
      "source": [
        "#### 6. Random Forest Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gUFM9n9SHWle"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uspgSN06HuuY"
      },
      "source": [
        "##### This initializes a random forest classifier with 50 decision trees and a random state of 2 for reproducibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPvdbWkcH4Ea"
      },
      "source": [
        "#### 7. AdaBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "nNKL_8WSHsk5"
      },
      "outputs": [],
      "source": [
        "abc = AdaBoostClassifier(n_estimators=50, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdKrcZrGI3f6"
      },
      "source": [
        "##### - This initializes an AdaBoost classifier with 50 decision trees as weak learners and a random state of 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6ZeYn9eI-iU"
      },
      "source": [
        "#### 8. Extra Trees Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qYspypf8I2dS"
      },
      "outputs": [],
      "source": [
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMv5WVMdJLa-"
      },
      "source": [
        "##### - This initializes an Extra Trees classifier with 50 trees in the forest and a random state of 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EElJtRJR_Q"
      },
      "source": [
        "#### 9. XGBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rURkC_hJJKQq"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(n_estimators=50, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shq9zCrKJayg"
      },
      "source": [
        "##### - This initializes an XGBoost classifier with 50 boosting rounds and a random state of 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2SO7nPJhAc"
      },
      "source": [
        "#### NOTE:\n",
        " Each model is now ready to be trained and evaluated on the dataset for the classification task. Adjust the hyperparameters as needed based on your specific task requirements and dataset characteristics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "53ZtwZt0JYuN"
      },
      "outputs": [],
      "source": [
        "# Initlize Models\n",
        "# Support Vector MAchine\n",
        "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
        "# KNeighbours\n",
        "knc = KNeighborsClassifier()\n",
        "# Multinomial NaiveBayes\n",
        "mnb = MultinomialNB()\n",
        "# Decision Tree\n",
        "dtc = DecisionTreeClassifier(max_depth=5)\n",
        "# Logistic Regression\n",
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "# Random Forest Classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
        "# AddaBoost Classifier\n",
        "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
        "# Extra Tree Classifier a Ensemble Method\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "# XGB Classifier\n",
        "xgb = XGBClassifier(n_estimators=50,random_state=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZxPXQF9LByx"
      },
      "source": [
        "##### The provided code fits each initialized model to the training data (X_train and y_train) and makes predictions on the test data (X_test). Here's a breakdown of the fitting and prediction process for each model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLNir73ELHX0"
      },
      "source": [
        "#### 1.Support Vector Machine (SVC):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tCoqRVMyK9Vk"
      },
      "outputs": [],
      "source": [
        "svc.fit(X_train, y_train)\n",
        "svc_pred = svc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n24g7Sz1ThXl"
      },
      "source": [
        "#### 2.K-Nearest Neighbors (KNN):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lKl_hyamTe-1"
      },
      "outputs": [],
      "source": [
        "knc.fit(X_train, y_train)\n",
        "knn_pred = knc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNUD9BEXTsDX"
      },
      "source": [
        "#### 3. Multinomial Naive Bayes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "HLhMLYV0Tqii"
      },
      "outputs": [],
      "source": [
        "mnb.fit(X_train, y_train)\n",
        "mnb_pred = mnb.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROqjGSC2T5Dv"
      },
      "source": [
        "#### 4.Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "esQmiFdRT4FV"
      },
      "outputs": [],
      "source": [
        "dtc.fit(X_train, y_train)\n",
        "dtc_pred = dtc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsApTCcOUHnr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFtynl4WUIK7"
      },
      "source": [
        "#### 5. Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DZ3LCZsRUA_0"
      },
      "outputs": [],
      "source": [
        "lrc.fit(X_train, y_train)\n",
        "lrc_pred = lrc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-dT7JJqUObu"
      },
      "source": [
        "#### 6.Random Forest Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vkd5kXI-UNh5"
      },
      "outputs": [],
      "source": [
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPaNGjwrUa2C"
      },
      "source": [
        "#### 7. AdaBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1uOm8js7UYlI"
      },
      "outputs": [],
      "source": [
        "abc.fit(X_train, y_train)\n",
        "abc_pred = abc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZAfiSwVbGN"
      },
      "source": [
        "#### 8. Extra Trees Classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lOswEGOEUj0H"
      },
      "outputs": [],
      "source": [
        "etc.fit(X_train, y_train)\n",
        "etc_pred = etc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToFwNVhZVmYn"
      },
      "source": [
        "#### 9. XGBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8KucLgK0VkLx"
      },
      "outputs": [],
      "source": [
        "xgb.fit(X_train, y_train)\n",
        "xgb_pred = xgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA8e4NUcV35x"
      },
      "source": [
        "## NOTE:\n",
        " For each model, the fit() method is used to train the model on the training data, and then the predict() method is used to make predictions on the test data. The predictions are stored in separate variables (svc_pred, knn_pred, etc.) for each model. These predictions can then be evaluated using appropriate evaluation metrics to assess the performance of each model on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "jU9xNkOgVuos"
      },
      "outputs": [],
      "source": [
        "# Fitting Each Model One by One\n",
        "# 1. SVC\n",
        "svc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "svc_pred = svc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 2. KNeighbours\n",
        "knc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "knn_pred = knc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 3. Multinomial NaiveBayes\n",
        "mnb.fit(X_train ,y_train)\n",
        "# Pred\n",
        "mnb_pred = mnb.predict(X_test)\n",
        "#-----------------------------\n",
        "# 4. Decision Tree\n",
        "dtc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "dtc_pred = dtc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 5. Logistic Regression\n",
        "lrc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "lrc_pred = lrc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 6. Random Forest Classifier\n",
        "rfc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "rfc_pred = rfc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 7. AddaBoost Classifier\n",
        "abc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "abc_pred = abc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 8.Extra Tree Classifier a Ensemble Method\n",
        "etc.fit(X_train ,y_train)\n",
        "# Pred\n",
        "etc_pred = etc.predict(X_test)\n",
        "#-----------------------------\n",
        "# 9. XGB Classifier\n",
        "xgb.fit(X_train ,y_train)\n",
        "# Pred\n",
        "xgb_pred = xgb.predict(X_test)\n",
        "#-----------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvvQozP4WNAp"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlSXepmtW3hH"
      },
      "source": [
        "#### 1.Define the evaluate Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Li_qruSHWLjK"
      },
      "outputs": [],
      "source": [
        "# def evaluate(y_test, y_pred):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNktad9RXCTG"
      },
      "source": [
        "#### - This line defines a function named evaluate that takes two arguments: y_test (true labels) and y_pred (predicted labels).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RkqRhh-XJBz"
      },
      "source": [
        "#### 2.Calculate Accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "H5-bpZsLXA99"
      },
      "outputs": [],
      "source": [
        "# accuracy = accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ax4zeIXRpS"
      },
      "source": [
        "##### - This line calculates the accuracy score by comparing the true labels (y_test) with the predicted labels (y_pred) using the accuracy_score function from scikit-learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAF7PyflXYPb"
      },
      "source": [
        "#### 3. Calculate Precision:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qB0nKcydXP2f"
      },
      "outputs": [],
      "source": [
        "# precision = precision_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxaFQ_fdXrZG"
      },
      "source": [
        "##### - This line calculates the precision score by comparing the true labels (y_test) with the predicted labels (y_pred) using the precision_score function from scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD2WXZANXza1"
      },
      "source": [
        "#### 4. Calculate Confusion Matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "BChdnW6YXiQu"
      },
      "outputs": [],
      "source": [
        "# confusion = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP6YGMLVX6L1"
      },
      "source": [
        "##### - This line calculates the confusion matrix by comparing the true labels (y_test) with the predicted labels (y_pred) using the confusion_matrix function from scikit-learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTxHKPwJYHWv"
      },
      "source": [
        "#### 5. Return Evaluation Metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Sbkv_kTcX4_-"
      },
      "outputs": [],
      "source": [
        "# return accuracy, precision, confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beeRNHUZYPLm"
      },
      "source": [
        "##### - This line returns the calculated accuracy, precision, and confusion matrix as a tuple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QtAAHoUYT1b"
      },
      "source": [
        "##### - This evaluate function can be used to assess the performance of a classification model by providing it with the true labels (y_test) and the predicted labels (y_pred). It will then return the accuracy, precision, and confusion matrix for the model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "44IdSGdzYN0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "def evaluate(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return accuracy, precision, confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HbYJ3NSaurU"
      },
      "source": [
        "#### 1. Support Vector Machine (SVC):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meHzLKKPaqZV",
        "outputId": "441e6897-7883-4d6b-d43b-860a9ed61240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of SVC is 0.8244073748902546, Precision Is 0.6363636363636364,\n",
            "Confusion Matrix is \n",
            "[[778  92]\n",
            " [108 161]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_SVC, precision_SVC, confusion_SVC = evaluate(y_test, svc_pred)\n",
        "print(f\"The Accuracy Score Of SVC is {accuracy_SVC}, Precision Is {precision_SVC},\\nConfusion Matrix is \\n{confusion_SVC} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbIRKs0Ja92d"
      },
      "source": [
        "##### - This code calculates and prints the accuracy, precision, and confusion matrix for the SVC model based on its predictions (svc_pred) on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4cmgC8ObCdZ"
      },
      "source": [
        "#### 2.K-Nearest Neighbors (KNN):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0q5oovAa16Y",
        "outputId": "fed6b650-e36f-4464-8a92-3e628258307c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of KNN is 0.8999122036874452, Precision Is 0.9144385026737968,\n",
            "Confusion Matrix is \n",
            "[[854  16]\n",
            " [ 98 171]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_KNN, precision_KNN, confusion_KNN = evaluate(y_test, knn_pred)\n",
        "print(f\"The Accuracy Score Of KNN is {accuracy_KNN}, Precision Is {precision_KNN},\\nConfusion Matrix is \\n{confusion_KNN} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuxcRJMgbMWT"
      },
      "source": [
        "##### - Similar to SVC, this code evaluates and prints the performance metrics for the KNN model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s7ZDiXWbTvn"
      },
      "source": [
        "#### 3. Multinomial Naive Bayes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPM1OQaxbJYi",
        "outputId": "fff126d7-735a-4a26-fed6-98c3879a6e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of MultinomialNB is 0.9894644424934153, Precision Is 0.9638989169675091,\n",
            "Confusion Matrix is \n",
            "[[860  10]\n",
            " [  2 267]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_MNB, precision_MNB, confusion_MNB = evaluate(y_test, mnb_pred)\n",
        "print(f\"The Accuracy Score Of MultinomialNB is {accuracy_MNB}, Precision Is {precision_MNB},\\nConfusion Matrix is \\n{confusion_MNB} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obeu2_26bfmN"
      },
      "source": [
        "###### - This code evaluates and prints metrics for the Multinomial Naive Bayes model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxyyAF15blp5"
      },
      "source": [
        "#### 4. Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lhjtoxLbc5h",
        "outputId": "71983a6f-6814-4e24-a4ba-9b1082b4dee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of Decision Tree is 0.9157155399473222, Precision Is 0.7694704049844237,\n",
            "Confusion Matrix is \n",
            "[[796  74]\n",
            " [ 22 247]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_DTC, precision_DTC, confusion_DTC = evaluate(y_test, dtc_pred)\n",
        "print(f\"The Accuracy Score Of Decision Tree is {accuracy_DTC}, Precision Is {precision_DTC},\\nConfusion Matrix is \\n{confusion_DTC} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhtap_QAiyY2"
      },
      "source": [
        "##### - Evaluates and prints metrics for the Decision Tree model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1LcwB9li7Zp"
      },
      "source": [
        "#### 5. Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGUw7cylilNK",
        "outputId": "f9fcaae7-bdd7-45d3-8e4b-5d64a3168808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of Logistic Regression is 0.9912203687445127, Precision Is 0.9850187265917603,\n",
            "Confusion Matrix is \n",
            "[[866   4]\n",
            " [  6 263]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_LR, precision_LR, confusion_LR = evaluate(y_test, lrc_pred)\n",
        "print(f\"The Accuracy Score Of Logistic Regression is {accuracy_LR}, Precision Is {precision_LR},\\nConfusion Matrix is \\n{confusion_LR} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1AcnhUUjDwu"
      },
      "source": [
        "##### - Evaluates and prints metrics for Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vbYUFwjJou"
      },
      "source": [
        "#### 6. Evaluates and prints metrics for Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcJznt8UjB_w",
        "outputId": "01cba368-dac9-4076-a606-2ee146b46f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of Random Forest Classifier is 0.9701492537313433, Precision Is 0.9957805907172996,\n",
            "Confusion Matrix is \n",
            "[[869   1]\n",
            " [ 33 236]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_RF, precision_RF, confusion_RF = evaluate(y_test, rfc_pred)\n",
        "print(f\"The Accuracy Score Of Random Forest Classifier is {accuracy_RF}, Precision Is {precision_RF},\\nConfusion Matrix is \\n{confusion_RF} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGgaUg0vjUOV"
      },
      "source": [
        "\n",
        "##### - Evaluates and prints metrics for the Random Forest Classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ernuu3TPja_2"
      },
      "source": [
        "#### 7. AdaBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4h4SC1jSIj",
        "outputId": "608ee6af-5878-479d-c02e-561e803e93c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of AdaBoost Classifier is 0.9552238805970149, Precision Is 0.8732876712328768,\n",
            "Confusion Matrix is \n",
            "[[833  37]\n",
            " [ 14 255]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_ADC, precision_ADC, confusion_ADC = evaluate(y_test, abc_pred)\n",
        "print(f\"The Accuracy Score Of AdaBoost Classifier is {accuracy_ADC}, Precision Is {precision_ADC},\\nConfusion Matrix is \\n{confusion_ADC} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDh9HSE-jlnK"
      },
      "source": [
        "##### - Evaluates and prints metrics for the AdaBoost Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FYLjMrBjrYf"
      },
      "source": [
        "#### 8. Extra Trees Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLe3JWf1jj_G",
        "outputId": "c7415eef-615a-48b4-d452-2e0be6f3cf11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of Extra Tree Classifier is 0.974539069359087, Precision Is 0.9958677685950413,\n",
            "Confusion Matrix is \n",
            "[[869   1]\n",
            " [ 28 241]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_ETC, precision_ETC, confusion_ETC = evaluate(y_test, etc_pred)\n",
        "print(f\"The Accuracy Score Of Extra Tree Classifier is {accuracy_ETC}, Precision Is {precision_ETC},\\nConfusion Matrix is \\n{confusion_ETC} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3WsQWyjj6GT"
      },
      "source": [
        "##### - Evaluates and prints metrics for the Extra Trees Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F68VWWUJkAty"
      },
      "source": [
        "#### 9. XGBoost Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBlwhuaKj0I6",
        "outputId": "44da80b2-2fb1-4a03-a955-81cfa354574a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of XGBoost Classifier is 0.9859525899912204, Precision Is 0.9846743295019157,\n",
            "Confusion Matrix is \n",
            "[[866   4]\n",
            " [ 12 257]] \n"
          ]
        }
      ],
      "source": [
        "accuracy_XGB, precision_XGB, confusion_XGB = evaluate(y_test, xgb_pred)\n",
        "print(f\"The Accuracy Score Of XGBoost Classifier is {accuracy_XGB}, Precision Is {precision_XGB},\\nConfusion Matrix is \\n{confusion_XGB} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXcpEXlnkL4W"
      },
      "source": [
        "##### - Evaluates and prints metrics for the XGBoost Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnfA-OxEkXLZ"
      },
      "source": [
        "## Note:\n",
        "This allows you to observe the performance of each model on the test data and compare their accuracy, precision, and confusion matrices. Adjustments to model hyperparameters or features can be made based on the observed results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZsK6s3fkS62",
        "outputId": "5af739d6-5bd9-438d-96b2-753c0b5aee3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Accuracy Score Of SVC is 0.8244073748902546 , Precision Is 0.6363636363636364 ,\n",
            "Confusion Matrix is \n",
            "[[778  92]\n",
            " [108 161]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of KNN is 0.8999122036874452 , Precision Is 0.9144385026737968 ,\n",
            "Confusion Matrix is \n",
            "[[854  16]\n",
            " [ 98 171]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of MultinomialNB is 0.9894644424934153 , Precision Is 0.9638989169675091 ,\n",
            "Confusion Matrix is \n",
            "[[860  10]\n",
            " [  2 267]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of Decision Tree is 0.9157155399473222 , Precision Is 0.7694704049844237 ,\n",
            "Confusion Matrix is \n",
            "[[796  74]\n",
            " [ 22 247]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of Logistic Regression is 0.9912203687445127 , Precision Is 0.9850187265917603 ,\n",
            "Confusion Matrix is \n",
            "[[866   4]\n",
            " [  6 263]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of Random Forest Classifier is 0.9701492537313433 , Precision Is 0.9957805907172996 ,\n",
            "Confusion Matrix is \n",
            "[[869   1]\n",
            " [ 33 236]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of AddaBoost Classifier is 0.9552238805970149 , Precision Is 0.8732876712328768 ,\n",
            "Confusion Matrix is \n",
            "[[833  37]\n",
            " [ 14 255]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of Extra Tree Classifier  is 0.974539069359087 , Precision Is 0.9958677685950413 ,\n",
            "Confusion Matrix is \n",
            "[[869   1]\n",
            " [ 28 241]] \n",
            "\n",
            "\n",
            "The Accuracy Score Of XGB Classifier is 0.9859525899912204 , Precision Is 0.9846743295019157 ,\n",
            "Confusion Matrix is \n",
            "[[866   4]\n",
            " [ 12 257]] \n"
          ]
        }
      ],
      "source": [
        "# Lets Evaluate Results One by One For Each\n",
        "# 1. SVC\n",
        "accuracy_SVC , precision_SVC , confusion_SVC = evaluate(y_test,svc_pred)\n",
        "print(f\"The Accuracy Score Of SVC is {accuracy_SVC} , Precision Is {precision_SVC} ,\\nConfusion Matrix is \\n{confusion_SVC} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. KNN\n",
        "accuracy_KNN , precision_KNN , confusion_KNN = evaluate(y_test,knn_pred)\n",
        "print(f\"The Accuracy Score Of KNN is {accuracy_KNN} , Precision Is {precision_KNN} ,\\nConfusion Matrix is \\n{confusion_KNN} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3.Multinomial\n",
        "accuracy_MNB , precision_MNB , confusion_MNB = evaluate(y_test,mnb_pred)\n",
        "print(f\"The Accuracy Score Of MultinomialNB is {accuracy_MNB} , Precision Is {precision_MNB} ,\\nConfusion Matrix is \\n{confusion_MNB} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4.Decision Tree\n",
        "accuracy_DTC , precision_DTC , confusion_DTC = evaluate(y_test,dtc_pred)\n",
        "print(f\"The Accuracy Score Of Decision Tree is {accuracy_DTC} , Precision Is {precision_DTC} ,\\nConfusion Matrix is \\n{confusion_DTC} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5.Logistic Regression\n",
        "accuracy_LR , precision_LR , confusion_LR = evaluate(y_test,lrc_pred)\n",
        "print(f\"The Accuracy Score Of Logistic Regression is {accuracy_LR} , Precision Is {precision_LR} ,\\nConfusion Matrix is \\n{confusion_LR} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 6.Random Forest Classifier\n",
        "accuracy_RF , precision_RF , confusion_RF = evaluate(y_test,rfc_pred)\n",
        "print(f\"The Accuracy Score Of Random Forest Classifier is {accuracy_RF} , Precision Is {precision_RF} ,\\nConfusion Matrix is \\n{confusion_RF} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 7.AddaBoost Classifier\n",
        "accuracy_ADC , precision_ADC , confusion_ADC = evaluate(y_test,abc_pred)\n",
        "print(f\"The Accuracy Score Of AddaBoost Classifier is {accuracy_ADC} , Precision Is {precision_ADC} ,\\nConfusion Matrix is \\n{confusion_ADC} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 8.Extra Tree Classifier a Ensemble Method\n",
        "accuracy_ETC , precision_ETC , confusion_ETC = evaluate(y_test,etc_pred)\n",
        "print(f\"The Accuracy Score Of Extra Tree Classifier  is {accuracy_ETC} , Precision Is {precision_ETC} ,\\nConfusion Matrix is \\n{confusion_ETC} \")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 9. XGB Classifier\n",
        "accuracy_XGB , precision_XGB , confusion_XGB = evaluate(y_test,xgb_pred)\n",
        "print(f\"The Accuracy Score Of XGB Classifier is {accuracy_XGB} , Precision Is {precision_XGB} ,\\nConfusion Matrix is \\n{confusion_XGB} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeXQfUOBPRx"
      },
      "source": [
        "#       DataFrame For Storing Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP0_OGjIBY0C"
      },
      "source": [
        "Creates a DataFrame named evaluation_df containing evaluation results (accuracy and precision) for each model. The DataFrame is sorted based on the Accuracy and Precision columns in descending order. Here's what each part of the code does:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTCh5k9_BcOO"
      },
      "source": [
        "1. Create a Dictionary with Evaluation Results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "S13DvsF4kK28"
      },
      "outputs": [],
      "source": [
        "evaluation_data = {\n",
        "    'Model': ['SVC', 'KNN', 'MultinomialNB', 'Decision Tree', 'Logistic Regression', 'Random Forest', 'AdaBoost', 'Extra Tree', 'XGBoost'],\n",
        "    'Accuracy': [accuracy_SVC, accuracy_KNN, accuracy_MNB, accuracy_DTC, accuracy_LR, accuracy_RF, accuracy_ADC, accuracy_ETC, accuracy_XGB],\n",
        "    'Precision': [precision_SVC, precision_KNN, precision_MNB, precision_DTC, precision_LR, precision_RF, precision_ADC, precision_ETC, precision_XGB]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljk3TWTJBqos"
      },
      "source": [
        "This dictionary contains model names ('Model'), their corresponding accuracy scores ('Accuracy'), and precision scores ('Precision')."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKQAbFF6Bt56"
      },
      "source": [
        "2. Create a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "5qkG4AG0knlm"
      },
      "outputs": [],
      "source": [
        "evaluation_df = pd.DataFrame(evaluation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIrtozqdB2tu"
      },
      "source": [
        "This line converts the dictionary evaluation_data into a DataFrame named evaluation_df.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4wpjCm9B6-i"
      },
      "source": [
        "3. Sort the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "PDqKL9qwB9-w"
      },
      "outputs": [],
      "source": [
        "evaluation_df = evaluation_df.sort_values(by=['Accuracy', 'Precision'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBemQZZwCCfQ"
      },
      "source": [
        "This line sorts the DataFrame evaluation_df based on the 'Accuracy' and 'Precision' columns in descending order. This will arrange the models with the highest accuracy and precision at the top of the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKhI4qz8CFeY"
      },
      "source": [
        "4. Display the Sorted DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xxhDbnmmCKMh",
        "outputId": "553705d6-f934-4914-c738-ab1baaaa54f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.991220</td>\n",
              "      <td>0.985019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>0.989464</td>\n",
              "      <td>0.963899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.985953</td>\n",
              "      <td>0.984674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Extra Tree</td>\n",
              "      <td>0.974539</td>\n",
              "      <td>0.995868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.970149</td>\n",
              "      <td>0.995781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.873288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.915716</td>\n",
              "      <td>0.769470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.899912</td>\n",
              "      <td>0.914439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.824407</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Accuracy  Precision\n",
              "4  Logistic Regression  0.991220   0.985019\n",
              "2        MultinomialNB  0.989464   0.963899\n",
              "8              XGBoost  0.985953   0.984674\n",
              "7           Extra Tree  0.974539   0.995868\n",
              "5        Random Forest  0.970149   0.995781\n",
              "6             AdaBoost  0.955224   0.873288\n",
              "3        Decision Tree  0.915716   0.769470\n",
              "1                  KNN  0.899912   0.914439\n",
              "0                  SVC  0.824407   0.636364"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMLyQ4ibCNUZ"
      },
      "source": [
        "- This line displays the sorted DataFrame evaluation_df, showing the model names along with their corresponding accuracy and precision scores, sorted in descending order of accuracy and precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XiVcuEWCVC5"
      },
      "source": [
        "Overall, this code provides a concise and organized summary of the evaluation results for each model, making it easier to compare their performance based on accuracy and precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "zP7iJ7tbCZLn",
        "outputId": "f8a0edde-97d5-4bdc-f672-5ac4caa51fcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.991220</td>\n",
              "      <td>0.985019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>0.989464</td>\n",
              "      <td>0.963899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.985953</td>\n",
              "      <td>0.984674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Extra Tree</td>\n",
              "      <td>0.974539</td>\n",
              "      <td>0.995868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.970149</td>\n",
              "      <td>0.995781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.873288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.915716</td>\n",
              "      <td>0.769470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.899912</td>\n",
              "      <td>0.914439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.824407</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Accuracy  Precision\n",
              "4  Logistic Regression  0.991220   0.985019\n",
              "2        MultinomialNB  0.989464   0.963899\n",
              "8              XGBoost  0.985953   0.984674\n",
              "7           Extra Tree  0.974539   0.995868\n",
              "5        Random Forest  0.970149   0.995781\n",
              "6             AdaBoost  0.955224   0.873288\n",
              "3        Decision Tree  0.915716   0.769470\n",
              "1                  KNN  0.899912   0.914439\n",
              "0                  SVC  0.824407   0.636364"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a dictionary with evaluation results\n",
        "evaluation_data = {\n",
        "    'Model': ['SVC', 'KNN', 'MultinomialNB', 'Decision Tree', 'Logistic Regression', 'Random Forest', 'AdaBoost', 'Extra Tree', 'XGBoost'],\n",
        "    'Accuracy': [accuracy_SVC, accuracy_KNN, accuracy_MNB, accuracy_DTC, accuracy_LR, accuracy_RF, accuracy_ADC, accuracy_ETC, accuracy_XGB],\n",
        "    'Precision': [precision_SVC, precision_KNN, precision_MNB, precision_DTC, precision_LR, precision_RF, precision_ADC, precision_ETC, precision_XGB]\n",
        "}\n",
        "\n",
        "# Create a dataframe\n",
        "evaluation_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "# Sort the dataframe based on Accuracy and Precision columns in descending order\n",
        "evaluation_df = evaluation_df.sort_values(by=['Accuracy', 'Precision'], ascending=False)\n",
        "\n",
        "# Display the sorted dataframe\n",
        "evaluation_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjuHU53ZCg1l",
        "outputId": "95c60b58-c833-4be6-cd51-e988ec1b226d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As we can see Out of All The Models , XGB is Performing State Of the Art With The Accuracy Of 0.9859525899912204 and Precision of 0.9846743295019157\n"
          ]
        }
      ],
      "source": [
        "print(f\"As we can see Out of All The Models , XGB is Performing State Of the Art With The Accuracy Of {accuracy_XGB} and Precision of {precision_XGB}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IvtkUusCmVV"
      },
      "source": [
        "As we can see Out of All The Models , XGB is Performing State Of the Art With The Accuracy Of 0.9757751937984496 and Precision of 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUe1y6gTCpt-"
      },
      "source": [
        "#               Visualizing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement portly (from versions: none)\n",
            "ERROR: No matching distribution found for portly\n"
          ]
        }
      ],
      "source": [
        "!pip install portly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vCJmY9ZwC1rB",
        "outputId": "007b0242-436f-4bf3-f8b4-c6d34d460f01"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plotly'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgo\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Define the models and their accuracies and precisions\u001b[39;00m\n\u001b[32m      4\u001b[39m models = [\u001b[33m'\u001b[39m\u001b[33mSVC\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mKNN\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMultinomialNB\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDecision Tree\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAdaBoost\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mExtra Tree\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'"
          ]
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define the models and their accuracies and precisions\n",
        "models = ['SVC', 'KNN', 'MultinomialNB', 'Decision Tree', 'Logistic Regression', 'Random Forest', 'AdaBoost', 'Extra Tree', 'XGBoost']\n",
        "accuracies = [accuracy_SVC, accuracy_KNN, accuracy_MNB, accuracy_DTC, accuracy_LR, accuracy_RF, accuracy_ADC, accuracy_ETC, accuracy_XGB]\n",
        "precisions = [precision_SVC, precision_KNN, precision_MNB, precision_DTC, precision_LR, precision_RF, precision_ADC, precision_ETC, precision_XGB]\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add bar traces for accuracy and precision\n",
        "fig.add_trace(go.Bar(\n",
        "    x=models,\n",
        "    y=accuracies,\n",
        "    name='Accuracy',\n",
        "    marker_color='skyblue'\n",
        "))\n",
        "fig.add_trace(go.Bar(\n",
        "    x=models,\n",
        "    y=precisions,\n",
        "    name='Precision',\n",
        "    marker_color='salmon'\n",
        "))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Accuracy and Precision of Different Models',\n",
        "    xaxis=dict(title='Models'),\n",
        "    yaxis=dict(title='Score'),\n",
        "    barmode='group'  # Group bars for each model\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQcNOAGcDkxf"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qQSJfhP_Do5M",
        "outputId": "d4e91921-a672-4652-86f9-902d72d79ae6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "      <th>text_sent_token</th>\n",
              "      <th>stem_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject naturally irresistible corporate ident...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject naturally irresistible corporate iden...</td>\n",
              "      <td>subject natur irresist corpor ident lt realli ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject stock trading gunslinger fanny merril...</td>\n",
              "      <td>subject stock trade gunsling fanni merril muzo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject unbelievable new homes made easy im wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject unbelievable new homes made easy im w...</td>\n",
              "      <td>subject unbeliev new home made easi im want sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject 4 color printing special request addit...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject 4 color printing special request addi...</td>\n",
              "      <td>subject 4 color print special request addit in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject money get software cds software compat...</td>\n",
              "      <td>1</td>\n",
              "      <td>[subject money get software cds software compa...</td>\n",
              "      <td>subject money get softwar cd softwar compat gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam  \\\n",
              "0  subject naturally irresistible corporate ident...     1   \n",
              "1  subject stock trading gunslinger fanny merrill...     1   \n",
              "2  subject unbelievable new homes made easy im wa...     1   \n",
              "3  subject 4 color printing special request addit...     1   \n",
              "4  subject money get software cds software compat...     1   \n",
              "\n",
              "                                     text_sent_token  \\\n",
              "0  [subject naturally irresistible corporate iden...   \n",
              "1  [subject stock trading gunslinger fanny merril...   \n",
              "2  [subject unbelievable new homes made easy im w...   \n",
              "3  [subject 4 color printing special request addi...   \n",
              "4  [subject money get software cds software compa...   \n",
              "\n",
              "                                            stem_msg  \n",
              "0  subject natur irresist corpor ident lt realli ...  \n",
              "1  subject stock trade gunsling fanni merril muzo...  \n",
              "2  subject unbeliev new home made easi im want sh...  \n",
              "3  subject 4 color print special request addit in...  \n",
              "4  subject money get softwar cd softwar compat gr...  "
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DfAIb01MDsCp",
        "outputId": "ab370114-9993-4280-8f82-f459e244064c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'subject unbeliev new home made easi im want show homeown pre approv 454 169 home loan 3 72 fix rate offer extend uncondit credit way factor take advantag limit time opportun ask visit websit complet 1 minut post approv form look foward hear dorca pittman'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['stem_msg'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBhLMj5FD7xl",
        "outputId": "46e56d9c-61f5-4d38-bf3e-3feb37fee5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: 'hi' - Predicted Label: 0\n",
            "Text: 'wanted check see day going' - Predicted Label: 1\n",
            "Text: 'hope everything going well' - Predicted Label: 1\n",
            "Text: 'chance review document sent earlier' - Predicted Label: 0\n",
            "Text: 'looking forward hearing soon' - Predicted Label: 0\n",
            "Text: 'ill office 5 pm today' - Predicted Label: 1\n",
            "Text: 'let know need anything else' - Predicted Label: 0\n",
            "Text: 'thanks help project' - Predicted Label: 0\n",
            "Text: 'dont forget meeting tomorrow morning 9' - Predicted Label: 1\n",
            "Text: 'hope great weekend' - Predicted Label: 1\n",
            "Text: 'notes last discussion reference' - Predicted Label: 1\n",
            "Text: 'reminder submit report end day' - Predicted Label: 1\n",
            "Text: 'congratulations recent promotion' - Predicted Label: 1\n",
            "Text: 'lets catch coffee sometime week' - Predicted Label: 0\n",
            "Text: 'wishing fantastic day ahead' - Predicted Label: 1\n",
            "Text: 'thanks reaching ill get back soon possible' - Predicted Label: 1\n",
            "Text: 'could please provide update status project' - Predicted Label: 0\n",
            "Text: 'hope youre enjoying nice weather today' - Predicted Label: 0\n",
            "Text: 'looking forward team lunch tomorrow' - Predicted Label: 0\n",
            "Text: 'ive attached file requested email' - Predicted Label: 1\n",
            "Text: 'let know questions upcoming presentation' - Predicted Label: 0\n",
            "Text: 'hope relaxing weekend' - Predicted Label: 1\n",
            "Text: 'wanted remind deadline proposal submission' - Predicted Label: 0\n",
            "Text: 'thanks attention matter' - Predicted Label: 1\n",
            "Text: 'appreciate help task' - Predicted Label: 1\n",
            "Text: 'lets discuss details project meeting tomorrow' - Predicted Label: 0\n",
            "Text: 'hope day going smoothly' - Predicted Label: 1\n",
            "Text: 'ill office rest day please reach need anything' - Predicted Label: 1\n",
            "Text: 'could please review provide feedback draft document' - Predicted Label: 0\n",
            "Text: 'looking forward seeing conference next week' - Predicted Label: 0\n",
            "Text: 'thanks quick response' - Predicted Label: 1\n",
            "Text: 'lets plan meet next tuesday finalize budget' - Predicted Label: 0\n",
            "Text: 'hope productive day' - Predicted Label: 1\n",
            "Text: 'friendly reminder weekly team meeting tomorrow' - Predicted Label: 1\n",
            "Text: 'thanks cooperation project' - Predicted Label: 0\n",
            "Text: 'hope youre great start week' - Predicted Label: 0\n",
            "Text: 'please let know need clarification instructions' - Predicted Label: 0\n",
            "Text: 'looking forward training session later today' - Predicted Label: 0\n",
            "Text: 'thanks patience work issue' - Predicted Label: 1\n",
            "Text: 'hope youre feeling better soon' - Predicted Label: 1\n",
            "Text: 'wanted touch base regarding progress project' - Predicted Label: 0\n",
            "Text: 'let know need assistance presentation slides' - Predicted Label: 0\n",
            "Text: 'hope wonderful holiday season' - Predicted Label: 1\n",
            "Text: 'thanks understanding cooperation' - Predicted Label: 1\n",
            "Text: 'please review attached document let know thoughts' - Predicted Label: 0\n",
            "Text: 'looking forward upcoming team building event' - Predicted Label: 0\n",
            "Text: 'hope day going well far' - Predicted Label: 1\n",
            "Text: 'wanted say thank hard work project' - Predicted Label: 0\n",
            "Text: 'ill follow next week discuss action items' - Predicted Label: 0\n",
            "Text: 'thanks input brainstorming session' - Predicted Label: 1\n",
            "Text: 'hope youre relaxing evening' - Predicted Label: 1\n",
            "Text: 'please find requested information attached email' - Predicted Label: 1\n",
            "Text: 'looking forward working project' - Predicted Label: 0\n",
            "Text: 'naturally irresistible corporate identity lt really hard recollect company market full suqgestions information isoverwhelminq good catchy logo stylish statlonery outstanding website make task much easier promise havinq ordered iogo company automaticaily become world ieader isguite ciear without good products effective business organization practicable aim hotat nowadays market promise marketing efforts become much effective list clear benefits creativeness hand made original logos specially done reflect distinctive company image convenience logo stationery provided formats easy use content management system letsyou change website content even structure promptness see logo drafts within three business days affordability marketing break make gaps budget 100 satisfaction guaranteed provide unlimited amount changes extra fees surethat love result collaboration look portfolio interested' - Predicted Label: 1\n"
          ]
        }
      ],
      "source": [
        "# Predict Messgae\n",
        "text = [\n",
        "    \"Hi there! How are you doing?\",\n",
        "    \"Just wanted to check in and see how your day is going.\",\n",
        "    \"Hope everything is going well with you.\",\n",
        "    \"Did you have a chance to review the document I sent earlier?\",\n",
        "    \"Looking forward to hearing from you soon.\",\n",
        "    \"I'll be in the office until 5 PM today.\",\n",
        "    \"Let me know if you need anything else from me.\",\n",
        "    \"Thanks for your help with the project!\",\n",
        "    \"Don't forget about the meeting tomorrow morning at 9 AM.\",\n",
        "    \"Hope you had a great weekend!\",\n",
        "    \"Here are the notes from our last discussion for your reference.\",\n",
        "    \"Just a reminder to submit your report by the end of the day.\",\n",
        "    \"Congratulations on your recent promotion!\",\n",
        "    \"Let's catch up over coffee sometime this week.\",\n",
        "    \"Wishing you a fantastic day ahead!\",\n",
        "    \"Thanks for reaching out. I'll get back to you as soon as possible.\",\n",
        "    \"Could you please provide an update on the status of the project?\",\n",
        "    \"Hope you're enjoying the nice weather today.\",\n",
        "    \"Looking forward to our team lunch tomorrow.\",\n",
        "    \"I've attached the file you requested to this email.\",\n",
        "    \"Let me know if you have any questions about the upcoming presentation.\",\n",
        "    \"Hope you had a relaxing weekend!\",\n",
        "    \"Just wanted to remind you about the deadline for the proposal submission.\",\n",
        "    \"Thanks for your attention to this matter.\",\n",
        "    \"I appreciate your help with this task.\",\n",
        "    \"Let's discuss the details of the project during our meeting tomorrow.\",\n",
        "    \"Hope your day is going smoothly.\",\n",
        "    \"I'll be out of the office for the rest of the day. Please reach out if you need anything.\",\n",
        "    \"Could you please review and provide feedback on the draft document?\",\n",
        "    \"Looking forward to seeing you at the conference next week.\",\n",
        "    \"Thanks for your quick response!\",\n",
        "    \"Let's plan to meet next Tuesday to finalize the budget.\",\n",
        "    \"Hope you had a productive day!\",\n",
        "    \"Just a friendly reminder about our weekly team meeting tomorrow.\",\n",
        "    \"Thanks for your cooperation on this project.\",\n",
        "    \"Hope you're having a great start to the week.\",\n",
        "    \"Please let me know if you need any further clarification on the instructions.\",\n",
        "    \"Looking forward to the training session later today.\",\n",
        "    \"Thanks for your patience while we work through this issue.\",\n",
        "    \"Hope you're feeling better soon!\",\n",
        "    \"Just wanted to touch base regarding the progress of the project.\",\n",
        "    \"Let me know if you need any assistance with the presentation slides.\",\n",
        "    \"Hope you had a wonderful holiday season!\",\n",
        "    \"Thanks for your understanding and cooperation.\",\n",
        "    \"Please review the attached document and let me know your thoughts.\",\n",
        "    \"Looking forward to the upcoming team building event.\",\n",
        "    \"Hope your day is going well so far.\",\n",
        "    \"Just wanted to say thank you for your hard work on this project.\",\n",
        "    \"I'll follow up with you next week to discuss the action items.\",\n",
        "    \"Thanks for your input during the brainstorming session.\",\n",
        "    \"Hope you're having a relaxing evening!\",\n",
        "    \"Please find the requested information attached to this email.\",\n",
        "    \"Looking forward to working with you on this project.\",\n",
        "    \"naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\"\n",
        "]\n",
        "\n",
        "# Preprocess Text\n",
        "preprocessed_text = []\n",
        "for txt in text:\n",
        "    # Lower case\n",
        "    txt = txt.lower()\n",
        "    # Remove punctuation\n",
        "    txt = txt.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    txt = ' '.join([word for word in txt.split() if word not in stopwords.words('english')])\n",
        "    preprocessed_text.append(txt)\n",
        "\n",
        "# Vectorize the preprocessed messages using the same vectorizer used during training\n",
        "X_input = cv.transform(preprocessed_text).toarray()\n",
        "\n",
        "# Predict the class label for the vectorized text messages\n",
        "predicted_labels = xgb.predict(X_input)\n",
        "\n",
        "# Print the predicted label for each message\n",
        "for idx, txt in enumerate(preprocessed_text):\n",
        "    if predicted_labels[idx] == 0:\n",
        "        print(f\"Text: '{txt}' - Predicted Label: 0\")\n",
        "    else:\n",
        "        print(f\"Text: '{txt}' - Predicted Label: 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4EVt7yBpEq5"
      },
      "source": [
        "# Use a Function for Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD7LP6KjpR6D"
      },
      "source": [
        "Encapsulating preprocessing logic so it's reusable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "jHnzX41voYdp"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "def preprocess_text(text_list):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    processed = []\n",
        "    for txt in text_list:\n",
        "        txt = txt.lower()\n",
        "        txt = txt.translate(str.maketrans('', '', string.punctuation))\n",
        "        txt = ' '.join([word for word in txt.split() if word not in stop_words])\n",
        "        processed.append(txt)\n",
        "    return processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P90GqMsUoD2a"
      },
      "source": [
        "# Saving xgb model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtqtTIAVpqjs"
      },
      "source": [
        "Handling Vectorizer and Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X-TbABOucNN",
        "outputId": "8ff5b682-bac2-4104-d101-df1a6dac078d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming you used CountVectorizer or TfidfVectorizer\n",
        "joblib.dump(cv, 'vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwgtuPxLvWtU",
        "outputId": "53791ae2-5a54-4632-c842-bd43e41da656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['spam_classifier.pkl']"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(xgb, \"spam_classifier.pkl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "wF2zgVXjHC3s"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "cv = joblib.load('vectorizer.pkl')\n",
        "xgb = joblib.load('spam_classifier.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "a123nrdN1Unu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'3.9.1'"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0.1\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "print(xgboost.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (peaceenv)",
      "language": "python",
      "name": "peaceenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
